{"archive":{"blogPosts":[{"id":"/tester-cest-tricher","metadata":{"permalink":"/blog/tester-cest-tricher","editUrl":"https://blog.marticou.com/blog/blog/2025-01-10-Tester-cest-tricher/index.md","source":"@site/blog/2025-01-10-Tester-cest-tricher/index.md","title":"Tester c'est tricher, compiler c'est douter","description":"Dans cet article, nous allons voir le concept de Continuous Integration (CI), son interet et ses inconevnients","date":"2025-01-10T00:00:00.000Z","tags":[{"inline":true,"label":"c","permalink":"/blog/tags/c"},{"inline":true,"label":"git","permalink":"/blog/tags/git"},{"inline":true,"label":"CI","permalink":"/blog/tags/ci"}],"readingTime":1.44,"hasTruncateMarker":true,"authors":[{"name":"Vianney Marticou","title":"Mr.VyM @ EPITA","url":"https://github.com/mrvym","page":{"permalink":"/blog/authors/mrvym"},"socials":{"github":"https://github.com/mrvym"},"imageURL":"https://github.com/mrvym.png","key":"mrvym"}],"frontMatter":{"title":"Tester c'est tricher, compiler c'est douter","slug":"/tester-cest-tricher","tags":["c","git","CI"],"hide_title":false,"date":"2025-01-10T00:00:00.000Z","authors":["mrvym"]},"unlisted":false,"nextItem":{"title":"Introduction à Terraform avec Proxmox","permalink":"/blog/intro-terraform-proxmox"}},"content":"Dans cet article, nous allons voir le concept de Continuous Integration (CI), son interet et ses inconevnients\n## Histoire\nMais d'abord, comme a mon habitude, un petit point histoire.\n>  In 1999, Beck elaborated more in his first full book on Extreme Programming. CruiseControl, one of the first open-source CI tools, self-published source was released in 2001.\n## Pourquoi\nLe but d'une CI est de pouvoir faire des tests automatises et cela a chaque commit. On appelle cela, une Continuous Integration car cela revient a verifier qu'a chaque commit qui est fait, le code est toujours fonctionel. \nElle est surtout utile lors des merges requests, elle permet de verifier qu'il n'y a pas de breaking change.\n<!-- truncate --> \n### Fonctionnement \nJe dois d'abord, vous expliquez quelque mots de vocabulaire avant de pouvoir expliquer le fonctionnement.\n- Jobs : C'est une instance d'un docker qui execute un script. Cela peut etre du code, des tests ou bien juste un `echo`. \n// TODO : photo\n- Pipeline : C'est un ensemble de jobs qui sont executés par Gitlab a chaque commit.  \n// TODO : photo\n\nJe suppose que vous commencez a comprendre le fonctionnement d'une CI, le but est de lancer une instance pour chaque jobs et de verifier son return code. Si tout est bon, alors on lance le jobs suivant pour finir la pipeline. \n## Démonstration\nNous allons utiliser le format Gitlab, c'est un fichier `.yaml` que l'on nomme `.gitlab-ci.yml`. \n### Simple Compile\n```yaml\nimage: alpine:latest\n\nmyjobname: \n  - script: \n    - make\n```\n\n### Compile with flags\nPour compiler avec des flags spécifiques, soit vous avez un rule dans votre makefile qui le fait, soit vous pouvez le faire à la main.\n```yaml\nmyjobname_hard: \n  - script:\n    - CFLAGS=\"-Wall -Werror\" make\n    # or \n    - make compile_flags\n```\n## Criterion + flags\n### Before Scripts\n### Multi stages\n## Formatteur\n## Cache\nDans certains cas, cela peut etre utile de mettre un cache dans notre CI. \nLe cas typique est celui du JS. C'est inutile de re-telecharger le dossier `node-modules/` á chaque pipeline. \nCe dossier ou bien fichier sera donc sauvegarder entre chaque pipeline / jobs.\n\nVous pouvez neamoins le clean quand vous le souhaitez.\n## Artefact ?\nbenchmarking in a ci\n## Coverage ?\n\n## Custom base\nVous avez pu voir que depuis le debut de cette article, nous ne precisons pas d'environment de CI. J'avais dit qu'une CI utilisait un docker mais lequel ? \n\nIl suffit de preciser cela, au debut de notre fichier de configuration. Vous pouvez utiliser n'importe quelle image docker, quelle soit public ou privée. \n```yaml\nimage: alpine:latest\n```"},{"id":"intro-terraform-proxmox","metadata":{"permalink":"/blog/intro-terraform-proxmox","editUrl":"https://blog.marticou.com/blog/blog/2024-12-02-intro-terraform-proxmox.md","source":"@site/blog/2024-12-02-intro-terraform-proxmox.md","title":"Introduction à Terraform avec Proxmox","description":"Le but de Terraform est de déployer une infrastructure ou une entité de manière idempotente. Cela signifie que l’on doit pouvoir relancer le script 100 fois et obtenir le même résultat à chaque exécution.","date":"2024-12-02T00:00:00.000Z","tags":[{"inline":true,"label":"terraform","permalink":"/blog/tags/terraform"},{"inline":true,"label":"proxmox","permalink":"/blog/tags/proxmox"},{"inline":false,"label":"devops","permalink":"/blog/tags/devops","description":"DevOps - Tools"},{"inline":true,"label":"hcl","permalink":"/blog/tags/hcl"},{"inline":true,"label":"BPG","permalink":"/blog/tags/bpg"}],"readingTime":3.5366666666666666,"hasTruncateMarker":true,"authors":[{"name":"Vianney Marticou","title":"Mr.VyM @ EPITA","url":"https://github.com/mrvym","page":{"permalink":"/blog/authors/mrvym"},"socials":{"github":"https://github.com/mrvym"},"imageURL":"https://github.com/mrvym.png","key":"mrvym"}],"frontMatter":{"slug":"intro-terraform-proxmox","title":"Introduction à Terraform avec Proxmox","tags":["terraform","proxmox","devops","hcl","BPG"],"authors":["mrvym"],"hide_title":false,"date":"2024-12-02T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Tester c'est tricher, compiler c'est douter","permalink":"/blog/tester-cest-tricher"},"nextItem":{"title":"Disque dur : SAS, SATA, SCSI ou IDE ?","permalink":"/blog/sas-or-not-sas"}},"content":"Le but de Terraform est de déployer une infrastructure ou une entité de manière **idempotente**. Cela signifie que l’on doit pouvoir relancer le script 100 fois et obtenir le même résultat à chaque exécution.  \nPour cela, nous utilisons un **provider**, qui est essentiellement une bibliothèque permettant de se connecter à notre serveur.\n\nDans ce cas pratique, nous allons utiliser **Proxmox** et **BPG**. Il existe deux principaux providers pour Proxmox :\n\n- **[Telmate](https://registry.terraform.io/providers/Telmate/proxmox/latest/docs)**  \n  C’est une bibliothèque qui permet de déployer très simplement des VMs et des LXCs.  \n  Inconvénient : elle n’implémente pas de fonctionnalités avancées. Cependant, elle est fréquemment mise à jour.\n  \n- **[Bpg](https://registry.terraform.io/providers/bpg/proxmox/latest/docs)**  \n  Cette bibliothèque est légèrement plus complexe à prendre en main, mais elle est bien plus puissante.\n\n<!-- truncate --> \n## Organisation et Structure d'un Projet Terraform \n\nAfin que vous puissiez mieux comprendre le projet, voici son architecture :\n\n```sh\n├── main.tf\n├── provider.tf\n├── variable.tf\n└── terraform.auto.tfvars\n```\n\nVous pouvez ajouter ou segmenter le projet en autant de fichiers `.tf` que nécessaire. Par exemple, nous aurions pu avoir un fichier pour les VMs et un autre pour les LXCs.\n\n- Les fichiers se terminant par `.tfvars` servent à définir des variables. Lorsqu’ils commencent par `auto`, ils sont automatiquement chargés par Terraform.  \n- Le fichier `variable.tf` permet de créer des variables sans les instancier.\n\n### Petit point Vocabulaire\nDans cette article, nous allons utiliser le terme de LXC et de VM. Je vais faire un petit point dessus.\n\n- **`LXC`** ou **`LinuX Container`** : ce sont des environnements virtualisés qui tourne sur le `kernel` de l'hôte mais qui ne peuvent pas discuter ensemble. Cela permet de segmenter nos services sans trop perde en performance.\n\n- **`VM`** ou **`Virtual Machine`** : comme son nom l'indique, on simule l'intégralité d'une machine. On perd en performance mais on gagne en sécurité et en fonctionnalité car un LXC n'a pas tout les privilèges.\n\n## Choisir et Configurer un Provider Proxmox\n\nAvant tout, nous devons installer le **provider** (la bibliothèque). Bien entendu, nous fixons une version minimale :  \n\n```hcl\nterraform {\n  required_providers {\n    proxmox = {\n      source  = \"bpg/proxmox\"\n      version = \">= 0.3.0\"\n    }\n  }\n  required_version = \">= 0.14\"\n}\n```\n\nUne fois la bibliothèque ajoutée, nous déclarons un provider nommé \"proxmox\", en fournissant les informations nécessaires :  \n\n```hcl\nprovider \"proxmox\" {\n  endpoint = \"https://${var.proxmox_endpoint}:8006\"\n  api_token = var.api_token_secret\n\n  insecure = true # car un certificat TLS auto-signé est utilisé\n  ssh {\n    agent = true\n    username = terraform\n  }\n}\n```\n\n---\n\n## Les Variables dans Terraform\n\nSi vous êtes attentif, vous avez remarqué que nous utilisons l’objet `var.api_token_secret` dans le bloc du provider. Cette chaîne de caractères est définie dans le fichier `terraform.auto.tfvars`.  \n\nÀ la manière d’un fichier `.env`, ce fichier contient des valeurs sensibles et **ne doit pas être poussé sur le dépôt git** :  \n\n```hcl\n# terraform.auto.tfvars\napi_token_secret = \"terraform-prov@pve!terraform=TOKEN\"\n```\n\nDans le fichier `variable.tf`, nous définissons les variables et leur type.  \nVoici les principaux types disponibles :  \n\n- **number**\n- **string**\n- **list()** (ex. : `list(string)`)\n- **object**\n- **map**\n\nExemple :  \n\n```hcl\n# variable.tf\n\nvariable \"api_token_secret\" {\n  description = \"Secret token to connect Proxmox API\"\n  type        = string\n}\n\nvariable \"proxmox_endpoint\" {\n  description = \"The domain name of the Proxmox instance\"\n  type        = string\n  default     = \"proxmox.mysite.fr\"\n}\n```\n\n---\n\n## Les Images et les Templates\n\nPour démarrer nos entités, nous devons leur fournir un système d’exploitation.  \nNous téléchargeons automatiquement un fichier de template pour le LXC et un ISO avec **cloud-init** pour la VM.  \n\n> Si vous ne connaissez pas **cloud-init**, c’est une méthode permettant d’instancier des machines sans passer par l’installateur de l’OS.  \n\n```hcl\nresource \"proxmox_virtual_environment_download_file\" \"ubuntu_22-04_lxc\" {\n  content_type = \"vztmpl\"\n  datastore_id = \"local\"\n  node_name    = var.target_node\n  url          = \"http://download.proxmox.com/images/system/ubuntu-22.04-standard_22.04-1_amd64.tar.zst\"\n}\n\nresource \"proxmox_virtual_environment_download_file\" \"ubuntu_22-04_img\" {\n  content_type = \"iso\"\n  datastore_id = \"local\"\n  node_name    = var.target_node\n  url          = \"https://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-amd64.img\"\n}\n```\n\n---\n\n## On crée un Réseau Virtuel\nSi nous avons envie que nos ressources discutent entre elles, il nous faut un réseau.\n\nPour créer un adaptateur virtuel, il suffit d’appeler la ressource `proxmox_virtual_environment_network_linux_bridge` et de lui donner un nom :  \n\n```hcl\nresource \"proxmox_virtual_environment_network_linux_bridge\" \"internal_network\" {\n  node_name = var.target_node\n  name      = \"vmbr5\"\n  comment   = \"Internal Network\"\n}\n```\n\n---\n\n## Votre premier Container  \n\nPassons aux choses concrètes en instanciant un **LXC**. Pour cela, nous créons une ressource `proxmox_virtual_environment_container`.  \n\nAvec l’IaC, tout peut être configuré : le disque, la RAM, le serveur DNS, etc.  \n\n```hcl\nresource \"proxmox_virtual_environment_container\" \"first_lxc\" {\n  description   = \"Managed by Terraform - Mr.VyM\"\n  node_name     = var.target_node\n  start_on_boot = true\n  started       = true\n\n  vm_id = 101\n\n  cpu {\n    architecture = \"amd64\"\n    cores        = var.core_nb\n  }\n\n  disk {\n    datastore_id = \"storage\"\n    size         = var.disk_size\n  }\n\n  memory {\n    dedicated = var.memory_size\n    swap      = 0\n  }\n\n  operating_system {\n    template_file_id = proxmox_virtual_environment_download_file.ubuntu_22-04_lxc.id\n    type             = \"ubuntu\"\n  }\n\n  initialization {\n    hostname = \"mycontainer\"\n\n    dns {\n      servers = [\"1.1.1.1\", \"1.0.0.1\"]\n    }\n\n    ip_config {\n      ipv4 {\n        address = \"192.168.10.2/24\"\n        gateway = \"192.168.10.1\"\n      }\n    }\n\n    user_account {\n      keys     = [\"keys 1\", \"keys 2\"]\n      password = var.lxc_password\n    }\n  }\n\n  network_interface {\n    bridge = proxmox_virtual_environment_network_linux_bridge.internal_network.name\n    name   = \"eth0\"\n  }\n}\n```\n\n---\n\n## Et maintenant une VM  \n\nCréer une VM suit le même pattern que pour un LXC, avec quelques différences :  \n\n```hcl\nresource \"proxmox_virtual_environment_vm\" \"vm_template\" {\n  description = \"Managed by Terraform - Mr.VyM\"\n  node_name   = var.target_node\n\n  name        = \"MyDummyVM\"\n  vm_id       = 102\n\n  cpu {\n    cores = var.core_nb\n    type  = \"x86-64-v2-AES\"  # recommandé pour les CPU modernes\n  }\n\n  memory {\n    dedicated = var.memory_size\n    floating  = var.memory_size # active le ballooning\n  }\n\n  disk {\n    datastore_id = \"local\"\n    file_id      = proxmox_virtual_environment_download_file.ubuntu_22-04_img.id\n    interface    = \"scsi0\"\n    size         = var.disk_size\n  }\n\n  initialization {\n    ip_config {\n      ipv4 {\n        address = \"${var.base_subnet}.3/24\"\n        gateway = \"${var.base_subnet}.1\"\n      }\n    }\n\n    user_account {\n      keys     = [\"keys 1\", \"keys 2\"]\n      password = var.vm_password \n      username = \"mrvym\"\n    }\n\n    datastore_id = \"local\"\n  }\n\n  network_device {\n    bridge = proxmox_virtual_environment_network_linux_bridge.internal_network.name\n  }\n\n  operating_system {\n    type = \"l26\" # Linux Kernel\n  }\n}\n```\n\n---\n\n## On check et ca part en Prod\n\nEnfin, nous déployons le tout avec les commandes suivantes :  \n\n- **`terraform init`**  \n  Initialise Terraform, télécharge les providers et crée les fichiers `terraform.state` et `terraform.lock`. Ces fichiers stockent l’état des entités sur le serveur.  \n  Si ces fichiers sont absents, Terraform recrée les ressources, ce qui pourrait entraîner leur suppression et recréation.  \n\n- **`terraform fmt`**  \n  Formate le code pour garantir sa propreté.  \n\n- **`terraform plan`**  \n  Vérifie les actions que Terraform s’apprête à exécuter.  \n\n- **`terraform apply`**  \n  Applique les modifications.\n\n\n\n\n\n\n> Ecrit pour l'**`Avent of Tech`** de la [JECT](https://dev.to/ject)"},{"id":"sas-or-not-sas","metadata":{"permalink":"/blog/sas-or-not-sas","editUrl":"https://blog.marticou.com/blog/blog/2024-09-07-SAS-or-not-SAS/index.md","source":"@site/blog/2024-09-07-SAS-or-not-SAS/index.md","title":"Disque dur : SAS, SATA, SCSI ou IDE ?","description":"Notre but dans cet article est de mieux comprendre le concept des interfaces matérielles / programmation, des couches physiques et des jeux de commandes, et plus simplement des systèmes de stockage qui nous entourent.","date":"2024-11-07T00:00:00.000Z","tags":[{"inline":true,"label":"SSD","permalink":"/blog/tags/ssd"},{"inline":true,"label":"SAS","permalink":"/blog/tags/sas"},{"inline":true,"label":"Hardware","permalink":"/blog/tags/hardware"},{"inline":true,"label":"Storage","permalink":"/blog/tags/storage"}],"readingTime":4.026666666666666,"hasTruncateMarker":true,"authors":[{"name":"Vianney Marticou","title":"Mr.VyM @ EPITA","url":"https://github.com/mrvym","page":{"permalink":"/blog/authors/mrvym"},"socials":{"github":"https://github.com/mrvym"},"imageURL":"https://github.com/mrvym.png","key":"mrvym"}],"frontMatter":{"slug":"sas-or-not-sas","title":"Disque dur : SAS, SATA, SCSI ou IDE ?","tags":["SSD","SAS","Hardware","Storage"],"hide_title":false,"date":"2024-11-07T00:00:00.000Z","authors":["mrvym"]},"unlisted":false,"prevItem":{"title":"Introduction à Terraform avec Proxmox","permalink":"/blog/intro-terraform-proxmox"},"nextItem":{"title":"#define INC(a) INC(a+1)","permalink":"/blog/define-inc-a"}},"content":"Notre but dans cet article est de mieux comprendre le concept des interfaces matérielles / programmation, des couches physiques et des jeux de commandes, et plus simplement des systèmes de stockage qui nous entourent.\n\n<!-- truncate --> \nMais d'abord, un \"rapide\" récapitulatif de l'état actuel de nos périphériques de stockage :\n\n| Norme de stockage  | Interface matérielle        | Couche physique                          | Jeux de commandes                  |\n|--------------------|-----------------------------|------------------------------------------|------------------------------------|\n| PATA               | IDE (Integrated Drive Electronics) | Connecteur 40/44 broches, câble parallèle | ACS (ATA Command Set)              |\n| SATA               | SATA (Serial ATA)           | Connecteur SATA, câble série             | ACS (ATA Command Set)              |\n| SAS (Serial Attached SCSI) | SCSI (Small Computer System Interface) | Connecteur SAS, câble série              | SCSI (Small Computer System Interface) |\n| NVMe (Non-Volatile Memory Express) | PCIe (Peripheral Component Interconnect Express) | Bus PCIe | AHCI (Advanced Host Controller Interface) |\n\nSi vous vous demandez, oui, les constructeurs ont pris un malin plaisir à utiliser le même nom entre l'interface et la norme.\n\n--\nAvant de commencer, un point vocabulaire\n> Couche Physique : C'est le cable et le connecteur.\n\n> Interface Materielle : C'est la maniere de communiquer, attention ne pas confondre avec le \"language\". \n\n> Jeu de commandes : C'est le language utilisé.\n\nPour faire une analogie, si vous etes un humain (j'espere :thinking:), la couche physique c'est vos cordes vocales, l'interface materielle, c'est la maniere de faire vibrer vos cordes et le jeu de commandes, c'est le language utilisé. \n\n## Norme de stockage\n\n### ATA \n> Date : 1986  \n> Qui : Western Digital  \n\nATA signifie **Advanced Technology Attachment**.\n\nC'est le véritable concurrent du protocole SCSI. C'est aussi un ensemble de normes avec l'interface matérielle (IDE), la couche physique (PATA ou bien SATA) et les jeux de commandes (ACS).\n\nC'est une version plus low-cost de SCSI, qui avait pour but de réutiliser des éléments de ce dernier mais en simplifiant le connecteur (la couche physique) et le jeu d'instruction.\n\nContrairement au SAS, cette norme est en semi-duplex, ce qui signifie qu'elle ne peut exécuter qu'une seule action simultanément : soit lire, soit écrire.\n\n### SAS \n\n> Date : 1980  \n> Qui : Shugart / NCR Corporation  \n\nC'est un ensemble de normes qui s'applique sur les couches physiques et les jeux de commandes. \n\nNous devons revenir dans les années 80, à cette époque, il n'y a pas des milliers de façons de communiquer avec un périphérique de stockage. L'un d'entre eux est le protocole **SCSI** (Small Computer System Interface).\n\nC'est un protocole propriétaire mais très performant pour son temps. Son grand avantage est le fait de déporter la logique dans le périphérique, contrairement à ses concurrents qui utilisent allègrement la puissance de l'ordinateur. Et dans les années 80, on n'avait pas encore la puissance de calcul, ce protocole a donc été particulièrement apprécié par l'industrie.\n\nDe plus, la norme a l'avantage de pouvoir écrire en duplex, c'est-à-dire lire et écrire des données simultanément.\n\n## Interface matérielle\n\n### IDE\n\nIDE est une norme qui intègre le contrôleur de disque directement sur le disque dur lui-même. Avant IDE, les contrôleurs de disque étaient séparés, ce qui compliquait la configuration et limitait la compatibilité.  \nCela signifie qu'un disque dur est dit compatible IDE s'il possède une puce IDE.\n\n### SATA\n\nC'est une ré-implémentation de l'interface matérielle parallèle en série (Serial ATA).\n\n> Qu'est-ce qu'un port parallèle ?  \n> Contrairement au port série, un port parallèle peut transférer un ensemble de 8 bits à la fois sur huit fils différents.\n\nPour vous donner une idée de l'interface matérielle / couche physique.\n![PATA Pin-out](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/si132dwg6anuqybjfeal.png)\n\n### PCIe\n\nL'interface matérielle PCIe (Peripheral Component Interconnect Express) est une interface de communication utilisée principalement pour connecter des périphériques internes tels que des cartes graphiques, des cartes réseau et d'autres cartes d'extension.\n\nElle utilise un bus série, ce qui signifie que les données sont transmises bit par bit sur une seule ligne, contrairement aux anciennes interfaces parallèles.\n\nPCIe fonctionne avec des connecteurs spécifiques et des voies de transmission (lanes) qui permettent des transferts de données très rapides. \n\nLes cartes PCIe sont insérées dans des slots PCIe sur la carte mère, et l'interface est disponible en différentes versions (x1, x4, x8, x16) en fonction du nombre de voies utilisées, offrant ainsi une bande passante ajustée aux besoins des périphériques.\n\nPCIe est largement utilisé dans les systèmes modernes en raison de sa vitesse de transmission élevée, de sa flexibilité et de sa capacité à évoluer pour prendre en charge des dispositifs nécessitant des débits importants.\n\n## Couche physique\n\nGlobalement, c'est la partie la plus simple de l'article.  \n(Enfin, en électronique, ce n'est jamais simple).\n\nUne couche physique, cela signifie que c'est la norme qui régit la façon de réaliser le câble et le connecteur (cf Illustration du Pin-out)\n\n\n\nUne nappe IDE\n![Nappe IDE](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fu04kfy2js7vjn27lbpg.jpg)\nDans notre cas, c'est un câble dit \"IDE\".  \nCe genre de câble est la version parallèle, il contient 80 fils, ce qui permet de connecter deux appareils à la carte mère. Le premier sera appelé \"master\" et le deuxième \"slave\".\n\n\n![Master Slave PATA](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/10bq0ctd4sh4ettg1514.png)\nMais je ne vais pas détailler les différents câbles qui existent.\n\n## Jeux de commandes\n\n### ACS (Commandes)\n> Date : années 80  \n> Qui : Shugart / NCR Corporation\n\nLe **ATA Command Set** (ACS) est la liste des commandes que le système peut envoyer au périphérique.  \nOn pourrait citer comme exemples :  \n- WRITE_SECTOR  \n- SLEEP  \n- PACKET  \n- IDENTIFY PACKET DEVICE\n\n### SCSI\n\nACS étant un détournement du jeu de SCSI, on retrouve de grandes similitudes entre les deux jeux. Cependant, on peut les différencier en creusant un peu, notamment en ce qui concerne les rapports d'erreurs.\n\n### AHCI\n\n**AHCI** (Advanced Host Controller Interface) permet une communication optimisée entre le système d'exploitation et les périphériques de stockage, en offrant des fonctionnalités avancées comme le contrôle de file d'attente (pour améliorer les lectures/écritures simultanées) et le mode **NCQ** (Native Command Queuing), qui permet au disque de réorganiser les commandes d'entrée/sortie pour une performance maximale.\n\nCe jeu de commandes facilite également des fonctionnalités telles que la gestion de l'alimentation et le **hot-plug** (permettre l'ajout et le retrait de périphériques sans éteindre le système).\n\nAHCI a été conçu pour améliorer les performances et la gestion des périphériques de stockage SATA en optimisant l'utilisation des ressources et la vitesse des transferts.\n\n# Conclusion / Performance\n\nNous n'avons toujours pas parlé de la partie performance de ces différences, donc voici le mot de la fin.\n\n| Interface    | Vitesse max (Gb/s)       | Type de connexion | Utilisation principale                    |\n|--------------|--------------------------|-------------------|-------------------------------------------|\n| **SATA III** | 6 Gb/s                   | Série            | SSD et HDD domestiques                   |\n| **SAS**      | 22,5 Gb/s                | Série            | Disques professionnels et serveurs       |\n| **PCIe 5.0** | 32 Gb/s par ligne        | Série            | SSD NVMe internes                        |\n| **NVMe**     | Dépend de PCIe           | PCIe             | SSD haute performance                    |\n| **U.2**      | Selon PCIe (16-32 Gb/s)  | PCIe et NVMe     | Serveurs et stations de travail          |\n| **M.2**      | Selon PCIe (16-32 Gb/s)  | PCIe ou SATA     | Ordinateurs portables et de bureau       |\n| **Thunderbolt 3/4** | 40 Gb/s           | Série (USB-C)    | Stockage externe rapide                  |\n| **USB 4**    | 40 Gb/s                  | Série (USB-C)    | Stockage externe polyvalent              |"},{"id":"define-inc-a","metadata":{"permalink":"/blog/define-inc-a","editUrl":"https://blog.marticou.com/blog/blog/2024-08-17-Define-INC-a/index.md","source":"@site/blog/2024-08-17-Define-INC-a/index.md","title":"#define INC(a) INC(a+1)","description":"Le but de cet article est de vous faire découvrir le magnifique univers des macros en C.","date":"2024-08-17T00:00:00.000Z","tags":[{"inline":true,"label":"define","permalink":"/blog/tags/define"},{"inline":false,"label":"C Language","permalink":"/blog/tags/c","description":"The most wonderful language"},{"inline":true,"label":"macro","permalink":"/blog/tags/macro"}],"readingTime":4.993333333333333,"hasTruncateMarker":true,"authors":[{"name":"Vianney Marticou","title":"Mr.VyM @ EPITA","url":"https://github.com/mrvym","page":{"permalink":"/blog/authors/mrvym"},"socials":{"github":"https://github.com/mrvym"},"imageURL":"https://github.com/mrvym.png","key":"mrvym"}],"frontMatter":{"slug":"define-inc-a","title":"#define INC(a) INC(a+1)","tags":["define","C","macro"],"hide_title":false,"authors":["mrvym"]},"unlisted":false,"prevItem":{"title":"Disque dur : SAS, SATA, SCSI ou IDE ?","permalink":"/blog/sas-or-not-sas"},"nextItem":{"title":"Le Merveilleux Monde de Make","permalink":"/blog/merveilleux-monde-de-make"}},"content":"Le but de cet article est de vous faire découvrir le magnifique univers des macros en C.\n\n# Une directive préprocesseur\nEn C, les lignes qui commencent par un # sont interprétées par le compilateur lors de la compilation des fichiers sources. On les appelle des directives du préprocesseur. Les macros en font partie.\n\nPetit point historique : \n> Les macros en langage C ont été introduites avec la première norme du langage C, appelée ANSI C (ou C89), \n> qui a été standardisée par l'[American National Standards Institute](https://www.ansi.org) (ANSI) en 1989.\n> \n> Cependant, avant cette standardisation, les macros faisaient déjà partie du langage C classique (ou K&R C) utilisé dans les années 1970. \n> Le compilateur C original, développé par Dennis Ritchie pour le système d'exploitation UNIX, incluait déjà une forme rudimentaire de macros via le préprocesseur, permettant des définitions avec #define.\n\n<!-- truncate --> \n# Define \n```c\n#define SENS_DE_LA_VIE 3.14\n\n/* ... */\n\nprintf(\"%f\\n\", SENS_DE_LA_VIE);\n```\nLe `define` a un fonctionnement assez simple à comprendre : le compilateur remplace toutes les occurrences dans le code par la valeur définie. Il fonctionne avec la syntaxe suivante `#define <MACRO_NAME> <value>`. On a pour convention de mettre le nom en majuscule, la valeur quant à elle est optionnelle.\n\nUn peu comme un \"Ctrl-f et remplacer\".\n\n## Mama, la macro\nOn peut utiliser les `define` pour définir des fonctions que l'on pourra utiliser dans notre code.\n\n```c\n#define INC(a) a++ \n#define MULTI_LINE(a,b) a = b; \\\n                        b = 0; \n\n\nINC(my_variable); \nMULTI_LINE(my_variable, foobar) \n// Je souligne le fait qu'il peut ne pas y avoir de ';' en fin de ligne \n\n// Cela donnera  \nmy_variable++;\nmy_variable = foobar;\nfoobar = 0;\n```\n\n## If or not if\nNous pouvons déclarer des macros de manière conditionnelle. \nSi un nom est déjà défini alors on exécute le bout de code suivant. \n```c\n#ifdef DEBUG\n// Je souligne qu'il est rarement conseillé d'utiliser des printf() en debug\n// et que nous avons brisé la règle du nom des macros en MAJ.\n#define return printf(\"(%s:%d)\\n\", __FUNCTION__, __LINE__);  return\n#endif /* ! DEBUG */\n\nint main(void) {\n    return 1;\n}\n```\nDans ce cas, j'utilise un `#ifndef`, mais il existe aussi :\n- `#ifdef`\n- `#if`\n- `#else`\n- `#elif`\n```c\n#if (X == 1)\n#define Y 2\n#elif (X == 2)\n#define Y \"Ami de la bonne blague, bonjour !\"\n#else\n#define Y NULL\n#endif /* ! X */\n\n/* ... */\n\nint main(void) {\n    #if (X == 1)\n    printf(\"%d\\n\", Y);\n    #else \n    printf(\"%s\\n\", Y);\n    #endif /* ! X */\n}\n```\n\nOn aime bien signaler avec un commentaire en bloc la fin des `#if`. C'est une convention qui permet de mieux se repérer dans le code. \n\n## Macros prédéfinies\nVous avez pu voir dans l'exemple précédent que j'utilisais les mots-clés `__FUNCTION__` et `__LINE__`. \nComme vous pouvez vous en douter, ce sont des macros que le compilateur va remplacer par la bonne valeur.\n\nIl existe une liste de macros prédéfinies [Common Predifined](https://gcc.gnu.org/onlinedocs/cpp/Common-Predefined-Macros.html).\n\nÀ noter qu'il existe des macros dites [System specific](https://gcc.gnu.org/onlinedocs/cpp/System-specific-Predefined-Macros.html).\n\nPetite liste non exhaustive : \n- `__DATE__` : Jan 14 2012\n- `__GNUC__` : Version majeure de GCC\n- `__TIME__` : 15:12:18\n- `__INCLUDE_LEVEL__` : La profondeur des includes en commençant par 0\n- `__BASE_FILE__` : Le nom du fichier actuel\n\n## Vers l'infini et au-delà des arguments\n```c\n// Ici, l'opérateur ## est l'opérateur de concaténation\n#define DEBUG_PRNTF(fmt, ...) printf(\"LOG\" ## fmt, __VA_ARGS__);\n```\nIci, on peut voir que l'on génère des macros variadiques, surtout utiles lors de la création de logs. \n(Même si ce n'est pas une bonne idée de faire des logs avec des `printf`.)\n\n## X-Macro\n\nPour cela, nous allons devoir créer un fichier externe, souvent nommé en `*.def` bien qu'il n'existe pas de convention.\n```c\n// color.def\nX(NC, \"\\e[0m\", \"No Color\", 0x000000) \nX(BLACK, \"\\e[0;30m\", \"Black\", 0x000000) \nX(GRAY, \"\\e[1;30m\", \"Gray\", 0x808080) \nX(RED, \"\\e[0;31m\", \"Red\", 0xFF0000) \nX(LIGHT_RED, \"\\e[1;31m\", \"Light Red\", 0xFF8080) \nX(GREEN, \"\\e[0;32m\", \"Green\", 0x00FF00) \nX(LIGHT_GREEN, \"\\e[1;32m\", \"Light Green\", 0x80FF80) \nX(BROWN, \"\\e[0;33m\", \"Brown\", 0xA52A2A) \nX(YELLOW, \"\\e[1;33m\", \"Yellow\", 0xFFFF00) \nX(BLUE, \"\\e[0;34m\", \"Blue\", 0x0000FF) \nX(LIGHT_BLUE, \"\\e[1;34m\", \"Light Blue\", 0xADD8E6) \nX(PURPLE, \"\\e[0;35m\", \"Purple\", 0x800080) \nX(LIGHT_PURPLE, \"\\e[1;35m\", \"Light Purple\", 0xEE82EE) \nX(CYAN, \"\\e[0;36m\", \"Cyan\", 0x00FFFF) \nX(LIGHT_CYAN, \"\\e[1;36m\", \"Light Cyan\", 0xE0FFFF) \nX(LIGHT_GRAY, \"\\e[0;37m\", \"Light Gray\", 0xD3D3D3) \nX(WHITE, \"\\e[1;37m\", \"White\", 0xFFFFFF)\n```\n\n```c\ntypedef struct {\n    const char *name;        \n    const char *ansi_code;  \n    const char *description;\n    unsigned int rgb;      \n} Color;\n\n#define X(NAME, ANSI, DESC, RGB) { #NAME, ANSI, DESC, RGB },\nColor colors[] = {\n    #include \"color.def\"\n};\n#undef X\n\n#define X(NAME, ANSI, DESC, RGB) printf(\"%s (%s) = %s\\n\", #NAME, DESC, #RGB);\nvoid print_colors() {\n    // Bien entendu, on pourrait itérer sur la structure créée mais c'est une illustration\n    #include \"color.def\"\n}\n#undef X\n```\nCe genre de macro est extrêmement utile. Je dois reconnaître qu'on la retrouve rarement dans un code source, mais elle permet de modifier le fonctionnement du programme sans pour autant devoir modifier le code source. Fun fact, elle est souvent utilisée dans la création de kernels. Elle permet de générer les structures globales comme l'IDT et la GDT.\n\n## Les problèmes \n__**Attention**__ : Petite mise au point d'abord, les macros sont des outils formidables mais il faut faire attention. Vous ne devez surtout pas utiliser ce genre de macro :\n```c\n#define MIN(a,b) (a < b ? a : b)\n```\n\nPrenons un exemple : `MIN(2 + 5, fibo(25))`\n### Problème n°1 \n`MIN(2 + 5, fibo(25))` => `(2 + 5 < fibo(25) ? 2 + 5 : fibo(25))`\n\nIci le problème est la priorité de calcul. Le compilateur va d'abord effectuer la comparaison puis l'addition, donc 2 + (1). On corrige cela par l'ajout de parenthèses en utilisant les arguments des macros.\n```c\n#define MIN(a,b) ((a) < (b) ? (a) : (b))\n```\nComme vous ne savez jamais ce que vos utilisateurs vont passer en paramètre, mettez toujours des parenthèses sur les arguments.\n### Problème n°2 \n`MIN(2 + 5, fibo(25))` => `(2 + 5 < fibo(25) ? 2 + 5 : fibo(25))`\n\nOn remarque que le compilateur fait un remplacement bête et méchant, ce qui veut dire que l'on va calculer deux fois `fibo(25)`. Je vous laisse imaginer si c'est une implémentation récursive.\n\nPour fixer ce problème, nous déclarons une variable intermédiaire avant le `if`. \n## Macros utiles\n\n```c\n#define MIN(a, b)                                                              \\\n    ({                                                                         \\\n        __typeof__(a) _a = a;                                                  \\\n        __typeof__(b) _b = b;                                                  \\\n        (_a) > (_b) ? (_b) : (_a);                                             \\\n    })\n\n#define ABS(a)                                                                 \\\n    ({                                                                         \\\n        __typeof__(a) _a = a;                                                  \\\n        0 < (_a) ? (_a) : -(_a);                                               \\\n    })\n\n#define MAX(a, b)                                                              \\\n    ({                                                                         \\\n        __typeof__(a) _a = a;                                                  \\\n        __typeof__(b) _b = b;                                                  \\\n        (_a) < (_b) ? (_b) : (_a);                                             \\\n    })\n\n#define CLAMP(a, x, b) MAX(a, MIN(x, b))\n// Pour les tableaux uniquement\n#define COUNT_OF(arr) sizeof(arr) / sizeof(arr[0])\n```\n\n## Là, on s'amuse\nIci, c'est du code purement overkill juste pour le fun. Je ne vous conseille pas forcément d'utiliser ces macros dans votre code.\nJe me fais juste plaisir (faut bien dans la vie).\n\n### Un auto free\n\n```c\n#define DEFER(free_call) __attribute__((cleanup(free_call)))\n\nvoid auto_free(void *ptr) {\n    void **p = (void **)ptr;\n    if (*p) {\n        free(*p);\n        *p = NULL;\n    }\n}\n\nint main() {\n  DEFER(auto_free) char* buffer = malloc(10);\n  return 0;\n}\n```\n\nJe vous laisse tester avec un petit `-fsanitize=address`. C'est vraiment une dinguerie. On pourrait même voir une amélioration de la fonction auto_free qui prend en paramètre une chaîne de caractères du nom de notre structure pour faire un switch.\n\n### Get time\n\nFonction plus chill où l'on calcule juste le temps d'exécution de notre fonction. Très utile pour faire du benchmark.\n\n```c\n#define MEASURE_TIME(block) {                                \\\n    clock_t start_time = clock();                            \\\n    block                                                    \\\n    clock_t end_time = clock();                              \\\n    double elapsed = ((double)(end_time - start_time)) / CLOCKS_PER_SEC * 1000.0; \\\n    printf(\"Execution time: %.3f ms\\n\", elapsed);            \\\n}\n```\n\n### Define Error\n\nPetite X-macro qui prend une macro en argument et qui l'expand.\n\n```c\n#define ERROR_LIST(X)          \\\n    X(ERROR_FILE_NOT_FOUND, \"File not found\")    \\\n    X(ERROR_INVALID_INPUT, \"Invalid input\")      \\\n    X(ERROR_OUT_OF_MEMORY, \"Out of memory\")      \\\n    X(ERROR_UNKNOWN, \"Unknown error\")\n\n#define DEFINE_ERROR_ENUM(code, message) code,\nenum ErrorCode {\n    ERROR_LIST(DEFINE_ERROR_ENUM)\n};\n\n#define DEFINE_ERROR_STRING(code, message) case code: return message;\nconst char* get_error_message(enum ErrorCode error_code) {\n    switch (error_code) {\n        ERROR_LIST(DEFINE_ERROR_STRING)\n        default: return \"Unrecognized error\";\n    }\n}\n\n/* ... */\nenum ErrorCode error = ERROR_OUT_OF_MEMORY;\nprintf(\"Error: %s\\n\", get_error_message(error));\n```\n\n### Génération de tests automatisés\n\nIci, on génère carrément des fonctions entières avec une macro, parce que le C n'a aucune limite. Moi aussi :eyes:\n```c\n#define GENERATE_TEST_FUNC(func, test_value, wanted_value) \\\n    void test_##func(void) { \\\n        printf(\"Test de \" #func \" avec valeur %d : \", test_value); \\\n        if (func(test_value)) { \\\n            printf(\"Succès\\n\"); \\\n        } else { \\\n            printf(\"Échec\\n\"); \\\n        } \\\n    }\n\n/* ... */\nGENERATE_TEST_FUNC(fibo, 10, 55);\n\ntest_fibo();\n```\n\n## RTFM\n\nIl est maintenant l'heure de conclure. Nous avons vu plein de choses très cool. Et si jamais vous êtes tentés, libre à vous de découvrir les macros par vous-même.\nDonc, conclusion : **RTFM**.\n\n> PS : Pour ce qui est du titre, les macros ne sont pas récursives, elles ne s'expandent qu'avec une profondeur de 1."},{"id":"merveilleux-monde-de-make","metadata":{"permalink":"/blog/merveilleux-monde-de-make","editUrl":"https://blog.marticou.com/blog/blog/2024-03-14-Merveilleux-Monde-de-Make/index.md","source":"@site/blog/2024-03-14-Merveilleux-Monde-de-Make/index.md","title":"Le Merveilleux Monde de Make","description":"Les Makefiles constituent un outil essentiel dans le développement de logiciels que ce soit en C/C++ ou autre. Ils permettent une gestion efficace des projets en automatisant le processus de compilation, de nettoyage et de tests.","date":"2024-03-14T00:00:00.000Z","tags":[{"inline":true,"label":"make","permalink":"/blog/tags/make"},{"inline":true,"label":"c","permalink":"/blog/tags/c"},{"inline":true,"label":"c++","permalink":"/blog/tags/c"},{"inline":true,"label":"criterion","permalink":"/blog/tags/criterion"}],"readingTime":5.753333333333333,"hasTruncateMarker":true,"authors":[{"name":"Vianney Marticou","title":"Mr.VyM @ EPITA","url":"https://github.com/mrvym","page":{"permalink":"/blog/authors/mrvym"},"socials":{"github":"https://github.com/mrvym"},"imageURL":"https://github.com/mrvym.png","key":"mrvym"}],"frontMatter":{"slug":"merveilleux-monde-de-make","title":"Le Merveilleux Monde de Make","authors":["mrvym"],"tags":["make","c","c++","criterion"]},"unlisted":false,"prevItem":{"title":"#define INC(a) INC(a+1)","permalink":"/blog/define-inc-a"},"nextItem":{"title":"IDEA / TODO / SUBJECT","permalink":"/blog/2030/01/01/TODO"}},"content":"Les Makefiles constituent un outil essentiel dans le développement de logiciels que ce soit en C/C++ ou autre. Ils permettent une gestion efficace des projets en automatisant le processus de compilation, de nettoyage et de tests. \n\nDans cet article, nous explorerons les bonnes pratiques pour la création et l'utilisation de Makefiles dans des projets C quelque soit leurs complexités.\n\n<!-- truncate -->\n### Make, ca sert a quoi ?\n\nMake est un programme qui a pour but de générer des fichier. Il permet de générer des pdfs, des exécutables et bien plus.\n\n> Dans les années 1970, la compilation des programmes devient de plus en plus longue et complexe, nécessitant de nombreuses étapes interdépendantes. La plupart des systèmes alors utilisés reposent sur des script shell, nécessitant de répéter toutes les étapes lors de la moindre correction. C'est dans ce contexte que Make fut développé par le docteur Stuart Feldman en 1977. En gérant les dépendances entre fichiers sources et fichiers compilés, Make permet de ne compiler que ce qui est nécessaire à la suite de la modification d'un fichier source.\n\nIl existe un makefile par défaut, qui définit un grand nombre de règles afin de générer la plupart des fichiers avec lesquels, vous serez amené a travailler.\n\nPour voir ce makefile, par défaut : `make -p`\n\n### Hello World \n\nPour débuter, nous allons prendre un cas très simple celui d'un fichier source unique, dans le même dossier que notre makefile. \n\n```sh\n.\n└── main.c \n```\nDans ce cas, il existe 2 facons de faire.\n\n```sh\n$ make main # Je souligne l'absence du .c\n```\n\nDans cette commande, nous demandons a make de créer le fichier `main`. Mais comment sait-il qu'il doit utiliser le fichier main.c pour faire notre binaire ? Cela est défini dans les règles par défaut.\n\nNous pouvons aussi creer un fichier `Makefile`\n\n```makefile=\n# Makefile\nmy_compilation_rule: \n    gcc main.c\n```\n\nUne fois, le fichier crée, il suffit d'exécuter la commande `make` (qui, par défaut, exécute la première règle du fichier).\nNous pouvons aussi mettre en argument le nom de la règle que nous voulons exécuter `make my_compilation_rule`.\n\n### Plus on est de fou, plus on rit\n\nNotre projet grossit, nous avons maintenant un deuxième fichier source.\n```sh\n.\n├── foo.c\n├── foo.h\n└── main.c \n```\n\nDans l'objectif de faire un makefile propre, nous allons déclarer une variable OBJ qui contiendra nos différents fichiers. On en profite pour déclarer un variable CC pour notre compilateur.\n\n```makefile\n# makefile\nCC = gcc\nOBJ = main.o foo.o\n\n\n# Cette variable sera utilisée dans la règle implicite qui compile les .o  \nCFLAGS = # My C Flags for the compiler\nLDFLAGS = # My linker flags\nTARGET = a.out\n\nall: $(OBJ)\n\t$(CC) $(OBJ) -o $(TARGET) $(LDFLAGS)\n```\n\nCette fois-ci, nous avons ajouter des dépendances à notre règle `all`. Maintenant, make sait qu'il faut d'abord faire les fichiers .o avant de pouvoir faire le linkage de tous les fichiers en un binaire.\n\n```makefile\n# makefile\nSRC = $(wildcard *.c) # main.c foo.c\nOBJ = $(SRC:.c=.o) # main.o foo.o\n```\n\nDans ce makefile, nous avons choisi de ne pas récupérer, à la main, les différents fichiers source. Nous récupérons automatiquement les fichiers source via la fonction `wildcard`. Cette fonction agit comme le globbing d'un shell. Dans cette example, elle récupère tous les fichiers terminant par `.c`. \n\nNous les convertissons en `.o` via cette syntax `$(NAME:old=new)` qui n'est rien de moins qu'un replace. La suite de notre makefile reste néanmoins la même chose.\n\n### Clean\n\nComme vous avez pu le remarquer, un makefile peut facilement générer un grand nombre de fichiers. C'est pour cela que nous allons créer une nouvelle règle dans notre makefile qui a pour but de supprimer tous les fichiers issus de la compilation. \n\n```makefile\n\n# ...\n\nclean: \n    $(RM) $(OBJ)\n    $(RM) $(TARGET)\n```\n\nPour les petits curieux qui se demandent ce que signifie la variable RM. C'est un simple alias avec la commande `rm -f`. Il faut savoir que cette variable peut très bien override. On peut très bien voir `RM = echo` ou bien `RM = mv to/path/` (à la place du remove), cela peut être très utile dans certains projets.\n\n#### Phony\n\nNous l'avons dit au début de cet article, mais make est un utilitaire qui permet de générer des fichiers. Mais que se passe-t-il, si l'on appelle la règle clean et qui existe un fichier `clean` dans notre dossier. \n```sh\nmake: 'clean' is up to date.\n```\n\nPour éviter ce genre de problème, il faut spécifier dans notre makefile que notre règle n'a pas pour but de générer un fichier. Pour cela, nous utilisons le mot clé `phony`.\n\nIl suffit d'écrire. \n```makefile\n.PHONY: my_rule1 my_rule12 # ... \n```\n\n### On range le repo\nMaintenant, que nous avons réussi à faire un makefile propre, nous allons pouvoir faire évoluer notre projet en mettant nos fichiers dans un dossier `src`.\n\n```\n.\n├── Makefile\n└── src/\n    ├── foo.c\n    ├── foo.h\n    └── main.c\n```\n\nPour cela, il nous suffit de rechercher la liste de nos .c dans le dossier src/ puis de les transformer en .o. On peut modifier le code que nous avons fait ci-dessus.\n\n```makefile=\nSRCDIR = src\nSRC = $(wildcard $(SRCDIR)/*.c)\nOBJ = $(SRC:$(SRCDIR)/%.c=$(SRCDIR)/%.o)\n# qui est équivalent à\n# OBJ = src/main.o \\\n#       src/main.o\n\n```\n\n### Where GDB ?\nIl peut être utile d'avoir un règle debug, afin de ne pas avoir à mettre un `-g` dans nos CFLAGS par défaut.\n\nPour cela, il suffit de :\n```makefile\ndebug: CFLAGS += -g\ndebug: all\n```\nOn remarque que la règle debug n'a pas de corps. Elle se contente d'ajouter un flag et d'appeler notre règle `all`.\n\n### Tester, c'est tricher \n\nPour cet article, nous allons voir comment faire un Makefile pour une test suite criterion.\n```\n.\n├── Makefile\n├── src/\n...\n└── tests/\n    └── foo_test.c\n```\n\nPour pouvoir lancer, nos tests, il va falloir que l'on trouve les fichiers source du dossier `tests`, puis linker tous nos fichiers en excluant le fichier main.o.\n\n```makefile\nTEST_DIR = tests\nSRC_TEST = $(wildcard $(TEST_DIR)/*.c)\nOBJ_TEST = $(SRC:$(TEST_DIR)/%.c=$(TEST_DIR)/%.o)\n\n# ... \n\ncheck: $(filter-out $(SRC_DIR)/main.o, $(OBJ)) $(OBJ_TEST)\n$(CC) $^ -o $(TARGET) $(LDFLAGS)\n```\nOn remarque que le fichier main.o est exclus en utilisant la fonction `filter-out`. On voit aussi l'appel d'une variable pour le moment inconnu. Il en existe un grand nombre.\n\n- `$^`  : La liste des dépendances de la règle\n\n- `$<` : Le nom de la première dépendance\n\n- `$@` : Le nom de la règle\n\n\n### On teste les tests\n\nSi l'on parle de test, nous devons forcément parler de coverage. Pour cela rien de plus simple, nous ajoutons les flags a nos variables puis exécutons `GCOVR`\n\n```makefile=\ncoverage: CFLAGS += -fPIC --coverage\ncoverage: LDFLAGS += -lgcov -lcriterion\ncoverage: check\ngcovr --print-summary\n```\n\n### Like a pro\nLa création d'un dossier build est la cerise sur le gâteau. Elle permet au développeur de faire `rm -rf build/` pour faire un clean.\n\nPour cela, nous allons devoir modifier notre variable `OBJ` et nous allons devoir créer un règle pour la compilation des .o. Nous ne pouvons plus utiliser les règles implicite.\n\n```makefile\nBUILD_DIR = build\nOBJ = $(SRC:$(SRC_DIR)/%.c=$(BUILD_DIR)/%.o)\n\n# Compilation des fichiers source\n$(BUILD_DIR)/%.o: $(SRC_DIR)/%.c | $(BUILD_DIR)\n$(CC) $(CFLAGS) -c $< -o $@\n    \n# Creer le repertoire de build\n$(BUILD_DIR):\nmkdir -p $(BUILD_DIR)\n```\nAlors on remarque que cette fois-ci, nous n'avons pas défini une règle, mais avec une variable. Nous avons même utilisé une sorte de regex pour la définir. \n\nNous avons aussi dû mettre un prérequis en plus, la règle $(build_dir). Le fait de mettre un `|` signifie qu'il doit d'abord vérifier qu'il est nécessaire de faire cette règle.\n\n## Bonus\n\n### Bibliothèque statique\nPour créer une bibliothèque statique à partir des fichiers source, vous pouvez ajouter des règles au Makefile :\n```makefile\nLIB_TARGET = libmylib.a\nLIB_OBJS = $(filter-out $(BUILD_DIR)/main.o, $(OBJS))\n\n$(LIB_TARGET): $(LIB_OBJS)\nar rcs $@ $^\n```\nUne fois, la librairie crée, vous pourrez simplement la link avec votre binaire.\n\n### Makefile récursif\nSi votre projet comporte des sous-modules, vous pouvez utiliser un Makefile récursif. Imaginons un projet avec la structure suivante.\n\n```sh\n.\n├── Makefile\n└── src/\n    ├── features1/\n        ...\n        └── Makefile\n    ├── features2/\n        ...\n        └── Makefile\n    ├── features3/\n        ...\n        └── Makefile\n    ├── features4/\n        ...\n        └── Makefile\n    ├── main.c\n    └── Makefile\n```\nPour cela, il y a deux approches possibles. La première serait de faire un seul makefile à la racine de notre projet et faire un find de nos fichiers .c. Nous verrons comment faire par la suite.\n\nLa deuxième, c'est de faire une structure récursif via le Makefile suivant. \n```makefile\n# src/makefile \nSUBDIRS = $(wildcard */.)\n\n.PHONY: subdirs $(SUBDIRS)\n\nsubdirs: $(SUBDIRS)\n\n$(SUBDIRS):\n    $(MAKE) -C $@\n```\n\nAvec ce fichier, nous allons pouvoir mettre un makefile dans chaque dossier features et lui et lui seul gérera la compilation de la features. Ils seront appelés par le `src/Makefile` via la règles subdirs.\n```makefile\n# Makefile\n\nexport CFLAGS = -Wall -Werror -pedantic\n\n# ...\n```\nN'oubliez pas d'export vos variables dans votre Makefile afin qu´elle s'applique sur les Makefiles suivants.\n\nCe genre d'architecture nécessite, la plupart du temps, de la combiner avec la création de librairie statique.\n### Répertoires infinis\n\nNous avons vu comment utiliser la fonction `wildcard` mais comment faire pour recuperer l'intégralité de nos fichiers sources ?\n\n```sh\n├── Makefile\n└── src/\n    └── foo/\n        └── bar/\n            ...\n                └── foobar/\n                    └── barfoo/\n                        └── here.c\n```\nLa prise en charge des répertoires \"infinis\" peut se faire via des règles génériques ou bien par l'intermédiaire d'un sub-shell.\n\nPar exemple :\n```makefile \n# Attention, il faut que votre systeme possede la command find\n\nSRC = $(shell find $(SRC_DIR) -name \"*.c\")\n```  \nou bien\n```makefile\n# Je laisse les plus aventureux d'entre vous dechiffrer ce code\n\nrwildcard = $(foreach d, $(wildcard $(1:=/*)), $(call rwildcard,$d,$2) $(filter $(subst *,%,$2),$d))\nSRC = $(rwildcard src,*.c)\n```\nou encore \n```makefile\nSRC = $(wildcard src/*.c) \\\n      $(wildcard src/*/*.c) \\\n      # ... # \n      $(wildcard src/*/*/*/*/*/*/*/*/*/*/.c)\n# S'il vous plait, ne faites pas ca \n```\n\n## $ make conclusion\n\nEn conclusion, l'utilisation judicieuse des Makefiles est cruciale pour la gestion efficace de projets. Il permet d'économiser énormément de temps lors du processus de développement. Ce n'est pas pour rien que la quasi-intégralité de l'industrie utilise cet outil. \n\nCette article n'étant bien entendu, pas exhaustif, je vous invite à vous renseigner par vous meme afin de découvrir les autres fonctionnalités de cet outil."},{"id":"/2030/01/01/TODO","metadata":{"permalink":"/blog/2030/01/01/TODO","editUrl":"https://blog.marticou.com/blog/blog/2030-01-01-TODO.mdx","source":"@site/blog/2030-01-01-TODO.mdx","title":"IDEA / TODO / SUBJECT","description":"include \"./ProtectPkill/ProtectPkill.md\"","date":"1970-01-01T00:00:00.000Z","tags":[],"readingTime":1.1766666666666667,"hasTruncateMarker":true,"authors":[{"name":"Vianney Marticou","title":"Mr.VyM @ EPITA","url":"https://github.com/mrvym","page":{"permalink":"/blog/authors/mrvym"},"socials":{"github":"https://github.com/mrvym"},"imageURL":"https://github.com/mrvym.png","key":"mrvym"}],"frontMatter":{"title":"IDEA / TODO / SUBJECT","authors":["mrvym"],"date":"1970-01-01T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Le Merveilleux Monde de Make","permalink":"/blog/merveilleux-monde-de-make"}},"content":"include \"./ProtectPkill/ProtectPkill.md\"\nPour les curieux, en recherche du sujet d'exploration \n<!-- truncate --> \n\n- [X] Fait\n- [ ] Libre \n\n## Hardware\n- [ ] I2C\n- [ ] SPI\n- [ ] UART\n- [X] Storage\n- [ ] Reverse engineering IOT\n- [ ] KICAD\n- [ ] STM32\n- [ ] InfintyBand\n\n## Toolchain\n- [X] Make\n- [ ] Autotools \n- [ ] CMake\n- [ ] Compilation Chain (C or RUST)\n- [ ] Interpeter\n- [ ] JIT\n\n## Deploy \n- [X] CI\n- [ ] CD\n- [ ] Docker \n- [ ] Compose\n- [x] Terraform\n- [ ] Ansible\n- [ ] Amazon RM\n- [ ] Puppet \n- [ ] Valgrand\n- [ ] Salt\n\n## Linux\n- [ ] Dual Boot\n- [ ] Arch Install\n- [ ] Nix install\n- [ ] Openstack\n- [ ] Kubernetes\n- [ ] K8s\n- [ ] K3s\n- [ ] Cube OS\n- [ ] BSD\n- [ ] Opensense vs Pfsense\n\n## Vim \n- [ ] Motion\n- [ ] Simple config\n- [ ] LSP\n- [ ] Simple syntax plugin\n\n## Proxmox\n- [X] IAC\n- [ ] Virtual Network + Namespace Linux\n- [ ] LXC\n- [ ] VM\n- [ ] FS (btrfs / ext4 / zfs)\n\n## Protocole \n- [ ] UDP / TCP\n- [ ] WebSocket\n- [ ] WebTransport\n- [ ] TLS\n- [ ] mTLS\n- [ ] Oauth2 \n\n## Utils\n- [ ] openssl\n- [ ] cat / head / tail \n- [ ] modprobe\n- [ ] systemctl\n- [ ] netplan\n- [ ] systemd\n\n## IA\n- [ ] NLP\n- [ ] Computer Vision\n- [ ] Transformer\n- [ ] Reseau de neurones convolutif\n- [ ] Perceptron (Les bases de l'ia)\n\n## Rabbit Hole\n- [ ] OIDC\n- [ ] Blockchain\n- [ ] Web 3.0\n- [ ] Web 4.0 \n- [ ] NFT\n- [ ] Voice-as-User Interface (VUI)\n- [ ] Metaverse\n- [ ] Cloud computing (RoCEE)"}]}}